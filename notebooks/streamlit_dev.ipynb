{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a6f241",
   "metadata": {},
   "source": [
    "# iDev for Streamlit app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7456111a",
   "metadata": {},
   "source": [
    "Space to work interactively with the inputs and filters involved in the streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1fd912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "if '../' not in sys.path:\n",
    "    sys.path.append('../')\n",
    "import os\n",
    "import glob\n",
    "import re \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "from z3950.PyZ3950 import zoom\n",
    "from z3950.Marc.marc_tools import Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e44438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p5_root = (\n",
    "    r\"G:\\DigiSchol\\Digital Research and Curator Team\\Projects & Proposals\\00_Current Projects\"\n",
    "    r\"\\LibCrowds Convert-a-Card (Adi)\\OCR\\20230504 TKB Export P5 175 GT pp\\1016992\\P5_for_Transkribus\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76baab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_df = pickle.load(open(\"C:\\\\Users\\\\HLloyd\\\\Downloads\\\\cards_df.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_df = pickle.load(open(\"cards_df.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7182be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfae0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(cards_df, open(\"cards_df.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c1f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = len(cards_df) - len(cards_df.dropna(subset=\"worldcat_matches\"))\n",
    "errors = len(cards_df.query(\"worldcat_matches == 'Error'\"))\n",
    "cards_to_show = cards_df.query(\"worldcat_matches != 'Error'\").dropna(subset=\"worldcat_matches\").loc[:,(\"title\", \"author\", \"shelfmark\", \"worldcat_matches\", \"lines\", \"selected_match\", \"match_needs_editing\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_to_show.iloc[40:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e688f",
   "metadata": {},
   "source": [
    "I checked if the Record dicts all have monotonically increasing keys, they do. I wondered if it was possible whether some might have been dropped as surrogate diagnostics but I guess not.\n",
    "\n",
    "`to_show[\"worldcat_result\"].apply(lambda x: pd.Index(list(x.keys())).is_monotonic_increasing)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_idx = 157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5480d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_ti = cards_to_show.loc[card_idx, 'title'].replace(' ', '+')\n",
    "if cards_to_show.loc[card_idx, 'author']:\n",
    "    search_au = cards_to_show.loc[card_idx, 'author'].replace(' ', '+')\n",
    "else:\n",
    "    search_au = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d55130",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_exists = bool(search_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea2b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_to_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe904c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = pd.DataFrame({\"record\": list(cards_to_show.loc[card_idx, \"worldcat_matches\"].values())})\n",
    "match_df[\"has_title\"] = match_df[\"record\"].apply(lambda x: bool(x.get_fields(\"245\")))\n",
    "match_df[\"has_author\"] = match_df[\"record\"].apply(lambda x: bool(x.get_fields(\"100\", \"110\", \"111\", \"130\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f560970",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.query(\"has_title == True and (has_author == True or not @au_exists)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match_df.loc[1, \"record\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_xml = requests.get(\"https://www.loc.gov/standards/codelists/languages.xml\")\n",
    "tree = ET.fromstring(lang_xml.text)\n",
    "lang_dict = {lang[2].text: lang[1].text for lang in tree[4]}\n",
    "\n",
    "lang_040b_re = re.compile(r\"\\$b[a-z]+\\$\")\n",
    "match_df[\"language_040$b\"] = match_df[\"record\"].apply(lambda x: lang_040b_re.search(x.get_fields(\"040\")[0].__str__()).group())\n",
    "match_df[\"language\"] = match_df[\"language_040$b\"].str[2:-1].map(lang_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9134c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = match_df.query(\"language in ['English', 'German']\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f37a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort options\n",
    "subject_access = [\"600\", \"610\", \"611\", \"630\", \"647\", \"648\", \"650\", \"651\", \"653\", \"654\", \"655\", \"656\", \"657\", \"658\", \"662\", \"688\"]\n",
    "\n",
    "filtered_df[\"num_subject_access\"] = filtered_df[\"record\"].apply(lambda x: len(x.get_fields(*subject_access)))\n",
    "filtered_df[\"num_linked\"] = filtered_df[\"record\"].apply(lambda x: len(x.get_fields(\"880\")))\n",
    "filtered_df[\"has_phys_desc\"] = filtered_df[\"record\"].apply(lambda x: bool(x.get_fields(\"300\")))\n",
    "filtered_df[\"good_encoding_level\"] = filtered_df[\"record\"].apply(lambda x: x.get_fields(\"LDR\")[0][17] not in [3, 5, 7])\n",
    "filtered_df[\"record_length\"] = filtered_df[\"record\"].apply(lambda x: len(x.get_fields()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba910692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_fields_idx(index):\n",
    "    if index.name == \"MARC Field\":\n",
    "        key = [0 if x == \"LDR\" else int(x) for x in index]\n",
    "        return key\n",
    "    elif index.name == \"Repeat Field ID\":\n",
    "        key = [x.split(\"$\")[1] if \"$\" in x else x for x in index]\n",
    "        return key\n",
    "\n",
    "\n",
    "def gen_unique_idx(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a unique index from one that contains repeated fields\n",
    "    @param df: pd.DataFrame\n",
    "    @return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    df[\"Repeat Field ID\"] = \"\"\n",
    "    dup_idx = df.index[df.index.duplicated()].unique()\n",
    "    unhandled_fields = [x for x in dup_idx if x not in [\"650\", \"880\"]]\n",
    "    if \"650\" in dup_idx:\n",
    "        str_add = df.loc[\"650\", df.columns[0]].copy()\n",
    "        str_add = [\" \" + str(x) for x in range(len(str_add))]\n",
    "        df.loc[\"650\", \"Repeat Field ID\"] = df.loc[\"650\", df.columns[0]].str.split(\" \").transform(lambda x: x[0]) + str_add\n",
    "    if \"880\" in dup_idx:\n",
    "        str_add = df.loc[\"880\", df.columns[0]].copy()\n",
    "        str_add = [\" \" + str(x) for x in range(len(str_add))]\n",
    "        df.loc[\"880\", \"Repeat Field ID\"] = df.loc[\"880\", df.columns[0]].str.split(\"/\").transform(lambda x: x[0]) + str_add\n",
    "    for dup in unhandled_fields:\n",
    "        df.loc[dup, \"Repeat Field ID\"] = [str(x) for x in range(len(df.loc[dup]))]\n",
    "\n",
    "    return df.set_index(\"Repeat Field ID\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_to_show = filtered_df#.sort_values(by=None, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d644364",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in range(3):\n",
    "    res = matches_to_show.iloc[i, 0].get_fields()\n",
    "    ldr = matches_to_show.iloc[i, 0].get_fields(\"LDR\")\n",
    "    col = pd.DataFrame(\n",
    "        index=pd.Index([\"LDR\"] + [x.tag for x in res], name=\"MARC Field\"),\n",
    "        data=ldr + [x.__str__()[6:] for x in res],\n",
    "        columns=[matches_to_show.iloc[i].name]\n",
    "    )\n",
    "    cols.append(gen_unique_idx(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.index.has_duplicates for x in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(cols, axis=1).sort_index(key=sort_fields_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cac]",
   "language": "python",
   "name": "conda-env-cac-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
